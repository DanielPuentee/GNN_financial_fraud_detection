{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Author: Daniel Puente Viejo*  \n",
    "\n",
    "<img src=\"https://cdn-icons-png.flaticon.com/512/5043/5043998.png\" width=\"100\" height=\"100\" float =\"right\">    \n",
    "\n",
    "This notebook explains the steps to generate the graph by applying the data already analysed and cleaned. The code on how to include new users is also provided.\n",
    "In any case, we have provided a series of scripts where you can run the latter with just one function: `graphs_management.py` \n",
    "- <a href='#1'><ins>1. Loading of Libraries and Data<ins></a>\n",
    "- <a href='#2'><ins>2. Split data<ins></a>\n",
    "- <a href='#2'><ins>3. Graph creation<ins></a>\n",
    "- <a href='#4'><ins>4. Graph save<ins> </a>\n",
    "- <a href='#5'><ins>5. New customer inclusion<ins> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='1'>1. Loading of Libraries and Data</a>\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Common libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, confusion_matrix, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch_geometric.data import HeteroData\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import Sequential, Linear, SAGEConv, to_hetero\n",
    "from torch.nn import ReLU\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Paths and warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "path = \"../data/eda_generated_data/\"\n",
    "output_path = \"../data/graph_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(path, file_name):\n",
    "    with open(path + file_name, 'rb') as f: return pickle.load(f)\n",
    "\n",
    "df_train = load_pickle(path, \"df_train.pkl\")\n",
    "df_val = load_pickle(path, \"df_val.pkl\")\n",
    "df_test = load_pickle(path, \"df_test.pkl\")\n",
    "scaler = load_pickle(path, \"scaler.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='2'>2. Split data</a>\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the graph will become very large and complex, only 10.000 transactions will be used for the graph creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_graph, _ = train_test_split(df_train, train_size = 8000, random_state = 40, stratify = df_train['TARGET'])\n",
    "df_val_graph, _ = train_test_split(df_val, train_size = 2000, random_state = 40, stratify = df_val['TARGET'])\n",
    "\n",
    "df_graph = pd.concat([df_train_graph, df_val_graph], axis = 0).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='3'>3. Graph creation</a>\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking into account that making relations of each feature individually would supose a huge amount of relations, the features are merged.   \n",
    "With the following function can be made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join(df, combination_list):\n",
    "\n",
    "    new_df = pd.DataFrame()\n",
    "    for i in combination_list:\n",
    "\n",
    "        df_with_selected_columns = df[list(i)]\n",
    "        name = '_'.join(i)\n",
    "        df_with_selected_columns[name] = df_with_selected_columns.apply(lambda x: ' '.join(x), axis=1)\n",
    "        new_df = pd.concat([new_df, df_with_selected_columns[name]], axis=1)\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This are the manual features that have been agrupated. Moreover, it has also been done a rename dictionary to make the names more readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_selection = [['ORGANIZATION_TYPE'], ['ORGANIZATION_TYPE', 'WEEKDAY_APPR_PROCESS_START'], ['NAME_INCOME_TYPE', 'FLAG_OWN_CAR', 'ORGANIZATION_TYPE'], \n",
    "                    ['FLAG_OWN_REALTY', 'ORGANIZATION_TYPE'], ['NAME_TYPE_SUITE', 'ORGANIZATION_TYPE'], ['NAME_CONTRACT_TYPE', 'ORGANIZATION_TYPE'], \n",
    "                    ['NAME_HOUSING_TYPE', 'NAME_EDUCATION_TYPE', 'ORGANIZATION_TYPE'], ['NAME_HOUSING_TYPE', 'NAME_FAMILY_STATUS', 'ORGANIZATION_TYPE']]\n",
    "                    \n",
    "rename_dict = {'ORGANIZATION_TYPE': 'organization', \n",
    "               'ORGANIZATION_TYPE_WEEKDAY_APPR_PROCESS_START': 'organization_weekday',\n",
    "               'NAME_INCOME_TYPE_FLAG_OWN_CAR_ORGANIZATION_TYPE': 'income_car_organization',\n",
    "               'FLAG_OWN_REALTY_ORGANIZATION_TYPE': 'realty_organization',\n",
    "               'NAME_TYPE_SUITE_ORGANIZATION_TYPE': 'suite_organization',\n",
    "               'NAME_CONTRACT_TYPE_ORGANIZATION_TYPE': 'contract_organization',\n",
    "               'NAME_HOUSING_TYPE_NAME_EDUCATION_TYPE_ORGANIZATION_TYPE': 'housing_education_organization',\n",
    "               'NAME_HOUSING_TYPE_NAME_FAMILY_STATUS_ORGANIZATION_TYPE': 'housing_family_organization'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe is created and shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>organization</th>\n",
       "      <th>organization_weekday</th>\n",
       "      <th>income_car_organization</th>\n",
       "      <th>realty_organization</th>\n",
       "      <th>suite_organization</th>\n",
       "      <th>contract_organization</th>\n",
       "      <th>housing_education_organization</th>\n",
       "      <th>housing_family_organization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business Entity Type 1</td>\n",
       "      <td>Business Entity Type 1 FRIDAY</td>\n",
       "      <td>Working Y Business Entity Type 1</td>\n",
       "      <td>N Business Entity Type 1</td>\n",
       "      <td>Unaccompanied Business Entity Type 1</td>\n",
       "      <td>Cash loans Business Entity Type 1</td>\n",
       "      <td>House / apartment Higher education Business En...</td>\n",
       "      <td>House / apartment Married Business Entity Type 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Business Entity Type 3</td>\n",
       "      <td>Business Entity Type 3 SATURDAY</td>\n",
       "      <td>Commercial associate Y Business Entity Type 3</td>\n",
       "      <td>Y Business Entity Type 3</td>\n",
       "      <td>Unaccompanied Business Entity Type 3</td>\n",
       "      <td>Cash loans Business Entity Type 3</td>\n",
       "      <td>House / apartment Higher education Business En...</td>\n",
       "      <td>House / apartment Married Business Entity Type 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Medicine</td>\n",
       "      <td>Medicine WEDNESDAY</td>\n",
       "      <td>Commercial associate N Medicine</td>\n",
       "      <td>Y Medicine</td>\n",
       "      <td>Family Medicine</td>\n",
       "      <td>Cash loans Medicine</td>\n",
       "      <td>House / apartment Secondary / secondary specia...</td>\n",
       "      <td>House / apartment Married Medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Business Entity Type 3</td>\n",
       "      <td>Business Entity Type 3 FRIDAY</td>\n",
       "      <td>Working N Business Entity Type 3</td>\n",
       "      <td>Y Business Entity Type 3</td>\n",
       "      <td>Unaccompanied Business Entity Type 3</td>\n",
       "      <td>Cash loans Business Entity Type 3</td>\n",
       "      <td>House / apartment Secondary / secondary specia...</td>\n",
       "      <td>House / apartment Married Business Entity Type 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Self-employed WEDNESDAY</td>\n",
       "      <td>Working N Self-employed</td>\n",
       "      <td>N Self-employed</td>\n",
       "      <td>Unaccompanied Self-employed</td>\n",
       "      <td>Cash loans Self-employed</td>\n",
       "      <td>House / apartment Secondary / secondary specia...</td>\n",
       "      <td>House / apartment Married Self-employed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             organization             organization_weekday  \\\n",
       "0  Business Entity Type 1    Business Entity Type 1 FRIDAY   \n",
       "1  Business Entity Type 3  Business Entity Type 3 SATURDAY   \n",
       "2                Medicine               Medicine WEDNESDAY   \n",
       "3  Business Entity Type 3    Business Entity Type 3 FRIDAY   \n",
       "4           Self-employed          Self-employed WEDNESDAY   \n",
       "\n",
       "                         income_car_organization       realty_organization  \\\n",
       "0               Working Y Business Entity Type 1  N Business Entity Type 1   \n",
       "1  Commercial associate Y Business Entity Type 3  Y Business Entity Type 3   \n",
       "2                Commercial associate N Medicine                Y Medicine   \n",
       "3               Working N Business Entity Type 3  Y Business Entity Type 3   \n",
       "4                        Working N Self-employed           N Self-employed   \n",
       "\n",
       "                     suite_organization              contract_organization  \\\n",
       "0  Unaccompanied Business Entity Type 1  Cash loans Business Entity Type 1   \n",
       "1  Unaccompanied Business Entity Type 3  Cash loans Business Entity Type 3   \n",
       "2                       Family Medicine                Cash loans Medicine   \n",
       "3  Unaccompanied Business Entity Type 3  Cash loans Business Entity Type 3   \n",
       "4           Unaccompanied Self-employed           Cash loans Self-employed   \n",
       "\n",
       "                      housing_education_organization  \\\n",
       "0  House / apartment Higher education Business En...   \n",
       "1  House / apartment Higher education Business En...   \n",
       "2  House / apartment Secondary / secondary specia...   \n",
       "3  House / apartment Secondary / secondary specia...   \n",
       "4  House / apartment Secondary / secondary specia...   \n",
       "\n",
       "                        housing_family_organization  \n",
       "0  House / apartment Married Business Entity Type 1  \n",
       "1  House / apartment Married Business Entity Type 3  \n",
       "2                House / apartment Married Medicine  \n",
       "3  House / apartment Married Business Entity Type 3  \n",
       "4           House / apartment Married Self-employed  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = join(df_graph, manual_selection)\n",
    "new_df.reset_index(drop=True, inplace=True)\n",
    "new_df.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "new_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the following functions every relation is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relations(new_df, feature, row):\n",
    "    filtrado = new_df[feature]\n",
    "    list_of_index_func = list(filtrado[filtrado == row[feature]].index)\n",
    "    \n",
    "    return list_of_index_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relations are:\n",
    "* **Self-loop:** The node is connected to itself.\n",
    "* **Bidirectional:** The node is connected to another node and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_creation(_user_list_user, new_df, test = None):\n",
    "    \n",
    "    if test == None: new_df_copy = new_df.copy()\n",
    "    else: new_df_copy = new_df.iloc[test:].copy()\n",
    "        \n",
    "    for k, row in enumerate(new_df_copy.iterrows()):\n",
    "        index, value = row\n",
    "\n",
    "        for x, cols in enumerate(new_df.columns): \n",
    "            list_of_index = get_relations(new_df, cols, value)\n",
    "\n",
    "            lenght_index = len(list_of_index)\n",
    "            _user_list_user[cols][0] += list_of_index\n",
    "            _user_list_user[cols][1] += list(np.full(lenght_index, index))\n",
    "\n",
    "    edges = [torch.tensor([np.array(v[0]), np.array(v[1])], dtype = torch.long) for k, v in _user_list_user.items()]\n",
    "\n",
    "    return edges\n",
    "\n",
    "_user_list_user = {i:[[],[]] for i in new_df.columns}\n",
    "edges = edge_creation(_user_list_user, new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numeric features are selected and scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_graph_numeric = df_graph.select_dtypes(include=['float64', 'int64'])\n",
    "df_graph_numeric_exclude = df_graph_numeric.drop(['SK_ID_CURR','TARGET'], axis=1)\n",
    "df_graph_numeric_exclude_scaled = scaler.transform(df_graph_numeric_exclude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all the information the graph is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1musers\u001b[0m={\n",
       "    x=[10000, 48],\n",
       "    y=[10000]\n",
       "  },\n",
       "  \u001b[1m(users, organization, users)\u001b[0m={ edge_index=[2, 10581492] },\n",
       "  \u001b[1m(users, organization_weekday, users)\u001b[0m={ edge_index=[2, 1659140] },\n",
       "  \u001b[1m(users, income_car_organization, users)\u001b[0m={ edge_index=[2, 4373766] },\n",
       "  \u001b[1m(users, realty_organization, users)\u001b[0m={ edge_index=[2, 6232718] },\n",
       "  \u001b[1m(users, suite_organization, users)\u001b[0m={ edge_index=[2, 7100622] },\n",
       "  \u001b[1m(users, contract_organization, users)\u001b[0m={ edge_index=[2, 8803078] },\n",
       "  \u001b[1m(users, housing_education_organization, users)\u001b[0m={ edge_index=[2, 5235818] },\n",
       "  \u001b[1m(users, housing_family_organization, users)\u001b[0m={ edge_index=[2, 3802318] }\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datas = HeteroData()\n",
    "\n",
    "datas['users'].x = torch.from_numpy(df_graph_numeric_exclude_scaled).float()\n",
    "datas['users'].y = torch.from_numpy(df_graph_numeric.TARGET.values).long()\n",
    "\n",
    "for k, v in zip(new_df.columns, edges): datas['users', k, 'users'].edge_index = v\n",
    "\n",
    "datas = T.ToUndirected()(datas)\n",
    "datas = T.AddSelfLoops()(datas)\n",
    "datas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally train and validation masks are created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask, val_mask = np.array([True] * 8000 + [False] * 2000), np.array([False] * 8000 + [True] * 2000)\n",
    "\n",
    "datas['users'].train_mask = torch.from_numpy(train_mask).bool()\n",
    "datas['users'].valid_mask = torch.from_numpy(train_mask).bool()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='4'>4. Graph save</a>\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(datas, output_path + 'training_graph.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle_file(file_name, file):\n",
    "    with open(output_path + file_name, 'wb') as f: pickle.dump(file, f)\n",
    "\n",
    "save_pickle_file('graph_df.pkl', new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='5'>5. New customer inclusion</a>\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train preprocessing is applied to the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_test(df_test):\n",
    "    df_test_cleaned = df_test[df_train.columns]\n",
    "    return df_test_cleaned\n",
    "\n",
    "df_test_cleaned = cleaning_test(df_test)\n",
    "df_test_cleaned = df_test_cleaned.iloc[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerical columns are selected and scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_cleaned_numeric = df_test_cleaned.select_dtypes(include=['float64', 'int64'])\n",
    "df_test_cleaned_numeric_exclude = df_test_cleaned_numeric.drop(['SK_ID_CURR','TARGET'], axis=1)\n",
    "df_test_cleaned_numeric_exclude_scaled = scaler.transform(df_test_cleaned_numeric_exclude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaled values are added to the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x_values = torch.from_numpy(df_test_cleaned_numeric_exclude_scaled).float()\n",
    "datas['users'].x = torch.cat((datas['users'].x, new_x_values))\n",
    "\n",
    "last_val = datas['users', 'organization', 'users']['edge_index'][1,-1].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The merged dataframe is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_cleaned.index = range(last_val+1, last_val+1 + len(df_test_cleaned))\n",
    "df_test_cleaned_colums_agregated = join(df_test_cleaned, manual_selection)\n",
    "df_test_cleaned_colums_agregated.rename(columns=rename_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The edges are obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df2 = pd.concat([new_df, df_test_cleaned_colums_agregated], axis=0)\n",
    "_user_list_user, length_test = {i:[[],[]] for i in new_df2.columns}, len(df_test_cleaned_colums_agregated)\n",
    "\n",
    "new_edges = edge_creation(_user_list_user, new_df2, -length_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A temporal merged graph is done so as to create biderectional relations and then contatenate with the big one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas_merge = HeteroData()\n",
    "\n",
    "for k, v in zip(new_df2.columns, new_edges): datas_merge['users', k, 'users'].edge_index = v\n",
    "datas_merge = T.ToUndirected()(datas_merge)\n",
    "datas_merge = T.AddSelfLoops()(datas_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edges are merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in enumerate(new_df2.columns):\n",
    "    previous_relation, new_relations = datas['users', v, 'users'].edge_index, datas_merge['users', v, 'users'].edge_index\n",
    "    new_relation = torch.cat((previous_relation, new_relations), dim=1)\n",
    "    datas['users', v, 'users'].edge_index = new_relation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test mask is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_new_mask = np.array([False] * (last_val+1) + [True] * len(df_test_cleaned_colums_agregated))\n",
    "datas['users'].test_mask = torch.from_numpy(test_new_mask).bool()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('reto10_rojo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08b3381ba778dce64d58ec8c6c249a117ea9c9228d0f8d8cd77d3c6ba08bc462"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
